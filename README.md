# Лабораторная работа №5. Многопоточный сервер

### Что делает сервер?
Сервер слушает порт и обрабатывает запросы клиентов. В качестве запроса клиент отправляет байт, который определяет эндпоинт. Сервер обрабатывает запрос, используя соответствующий хендлер, и отправляет ответ клиенту.
Реализованые эндпоинты:
- `e` – эхо. Отправляет клиенту его же сообщение.
- `u` – запрос загрузки файла. В первых 4 байтах необходимо передать размер файла в формате little-endian. После этого необходимо отправить сам файл в байтах. Сервер отправляет клиенту 32-байтовый токен, с помощью которого можно будет далее скачать файл в эндпоинте `d`.
- `d` – запрос скачивания файла. На вход принимает 32-байтовый токен, который был получен в эндпоинте `u`. Первые 4 байта ответа – размер файла в формате little-endian, после этого идет сам файл.
- `g` – запрос на генерацию графа. Если отправленный файл является списком смежности графа, то по нему можно запросить генерацию bmp-изображения графа (как в 4 лабораторной работе). Для этого необходимо отправить 32-байтовый токен, соответствующий файлу с графом. В ответ сервер отправит 32-байтовый токен, по которому далее можно будет скачать изображение графа в эндпоинте `d`.

На загрузку файлов и генерацию графа существуют некоторые ограничения:
- Максимальный размер файла для загрузки – 1 МБ.
- Максимальное количество вершин в графе – 200.
- Граф должен быть неориентированным, не содержать кратных ребер и петель. Также сам список смежности должен быть корректным.

Все эти проверки осуществляются в соответствующих хендлерах, и в случае ошибки клиенту отправляется соответствующий ответ.

### Замеры производительности
Для замеров производительности использовался скрипт `benchmark.py`. Для генерации используется максимально возможный граф – полный граф на 200 вершинах. Перед отправкой запроса загрузки файла список ребер перемешивается случайным образом, чтобы файлы получались уникальными. Замеры проводились как на локальной машине, так и на удаленном сервере. 
Для тестирования многопоточности сервера в 5 потоках запускались функции для бенчмаркинга, отправляющие 100 запросов каждого типа: загрузки файла, скачивания файла, генерации графа. В итоге бралось среднее время выполнения одного запроса.

Характеристики локальной машины: ноутбук MacBook Air на процессоре M1, 8 ГБ оперативной памяти типа DDR4, операционная система MacOS 14.4.

Характеристики удаленного сервера: виртуальный сервер на Intel Core i9-14900K, 8 ядер, 16 ГБ оперативной памяти типа DDR5, операционная система Ubuntu 24.04. Сервер находится в Москве, а тесты проводились из Санкт-Петербурга.

Также, перед тестированием была выдвинута следующая гипотеза: сервер будет хорошо работать с большим количеством одновременно подключенных клиентов, если много потоков, которые работают с клиентами будут спать. Такого можно добиться в случае, если клиенты отправляют запрос на генерацию графа, и у всех хендлеров генерации один общий пул потоков, куда они отправляют задачи на генерацию. 
Таким образом, поток, работающий с клиентом, засыпает, пока генерация не будет завершена. Если пул потоков, отвечающий за генерацию, содержит малое количество потоков, а пул потоков сервера – большое, то сервер сможет обрабатывать большое количество клиентов одновременно. Для ее тестирования в бенчмарке также запускалось 100 потоков, отправляющих запросы на генерацию графа.

#### Локальная машина

| Количество потоков сервера | Количество потоков генерации | Скорость загрузки | Скорость генерации | Скорость скачивания |
|----------------------------|------------------------------|-------------------|--------------------|---------------------|
| 1                          | 1                            | 932,49 мс         | 1295,01 мс         | 740,57 мс           |
| 2                          | 2                            | 503,67 мс         | 830,996 мс         | 230,29 мс           |
| 4                          | 2                            | 304,65 мс         | 1277,41 мс         | 12,574 мс           |
| 4                          | 4                            | 170,88 мс         | 779,34 мс          | 13,73 мс            |
| 6                          | 2                            | 23,34 мс          | 1513,97 мс         | 13,15 мс            |
| 8                          | 4                            | 33,71 мс          | 1043,14 мс         | 18,11 мс            |
| 8                          | 8                            | 36,05 мс          | 982,76 мс          | 19,99 мс            |
| 100                        | 100                          | 2288,54 мс        | 12126,52 мс        | 932,85 мс           |
| 100                        | 4                            | 59,12 мс          | 18629,29 мс        | 26,43 мс            |

Видно, что гипотеза оказалась верной: уменьшив количество потоков генерации, мы хоть и замедлили генерацию, но при этом существенно ускорили остальные запросы, а также сильно уменьшили количество потоков в системе. Таким образом, сервер справляется с большим количеством одновременно подключенных клиентов.
При использовании 6 потоков вместо 4 скорость загрузки резко вырастает, так как в бенчмарке использовалось 5 потоков для отправки запросов на сервер. При тестировании сервера на 100 потоках, в бенчмарке использовалось 100 потоков для отправки запросов на сервер.

#### Удаленный сервер

| Количество потоков сервера | Количество потоков генерации | Скорость загрузки | Скорость генерации | Скорость скачивания |
|----------------------------|------------------------------|-------------------|--------------------|---------------------|
| 1                          | 1                            | ?                 | ?                  | ?                   |
| 2                          | 2                            | ?                 | ?                  | ?                   |
| 4                          | 2                            | ?                 | ?                  | ?                   |
| 4                          | 4                            | ?                 | ?                  | ?                   |
| 8                          | 2                            | ?                 | ?                  | ?                   |
| 8                          | 4                            | ?                 | ?                  | ?                   |
| 8                          | 8                            | ?                 | ?                  | ?                   |
| 100                        | 100                          | ?                 | ?                  | ?                   |
| 100                        | 4                            | ?                 | ?                  | ?                   |


### Интересности
#### Пул потоков
Класс  `Server::Multithreading::ThreadPool` реализует пул потоков, позволяющий в удобном формате вычислять функции.
- ```ThreadPool(size_t _threads_count)``` – констуктор, создает _threads_count спящих потоков.
- `add_task(F&& task, Args&&... args)` – добавляет задачу в очередь на выполнение. Принимает на вход функцию, которую нужно выполнить и аргументы для нее. Возвращает объект `std::future<...>`,
где вместо `...` указан тип возвращаемого значения функции. Далее, когда результат будет готов, можно получить его вызовом метода `get()`.

#### Класс `Server::Server`
Класс `Server::Server` реализует многопоточный сервер, который слушает порт и обрабатывает запросы клиентов. В качестве аргумента конструктора принимает порт, на котором нужно слушать соединения, максимальное количество клиентов, ожидающих соединение и количество потоков в пуле потоков. Сколько будет потоков в пуле, столько клиентов сможет одновременно обрабатываться.

#### RAII-обертки для работы с сокетами
Классы `Server::ListenerSocket` и `Server::ClientSocket`, унаследованные от базового класса `Server::Socket` реализуют RAII-обертки для работы с сокетами. 
 - `Server::ListenerSocket` с помощью своего конструктора позволяет создать слушающий сокет, а с помощью метода `accept()` – принять соединение. Соединение возвращается в виде `std::shared_ptr<ClientSocket>`. 
Возвращается именно указатель, потому что все сокеты являются некопируемыми, и передача по значению невозможна. При этом, если возникнет необходимость написать lamda-функцию, работающую с таким сокетом, то функция будет [move-only](https://stackoverflow.com/questions/25330716/move-only-version-of-stdfunction), и сохранить ее в std::function уже не выйдет. Это накладывает существенные ограничения, поэтому возвращается именно shared_ptr.
 - `Server::ClientSocket` позволяет читать и писать данные в сокет. У него нет публичного конструктора, поэтому создать его можно только через `Server::ListenerSocket::accept()`. Класс предоставляет методы для чтения байтов с сокета и записи их туда же. 
 - `Server::Socket` – базовый класс, содержащий общие методы для работы с сокетами. Также именно в его деструкторе происходит закрытие файлового дескриптора, отвечающего за сокет.

#### Кастомные эндпоинты и хендлеры
Для написания собственных хендлеров достаточно просто унаследоваться от класса-интерфейса `Server::Handlers::IHandler` и реализовать метод `handle()`. 
Метод `handle()` не принимает на вход ничего, и возвращает `Server::Response`. Внутри метода можно использовать методы `read_byte()`, `read_bytes()`, `write_byte()`, `write_bytes()` для чтения и записи данных в сокет. Также, для удобного возврата ответа клиенту есть несколько готовых функций, возвращающие стандартные ответы: `not_found_response(), ok_response(), bad_request_response()` и еще несколько других.

Также, необходимо реализовать конструктор, принимающий на вход `Server::ClientSocket` первым аргументом. Остальные аргументы могут быть любые, в зависимости от того, что требуется для работы хендлера.

Далее, когда хендлер реализован, его можно добавить в сервер, вызвав шаблонный метод `add_handler()`. В качестве параметра шаблона необходимо передать тип хендлера, например, `Server::Handlers::EchoHandler`. Первый аргумент конструктора хендлера – это байт, который будет определять эндпоинт. Следующими аргументами можно передать любые данные, необходимые для создания объекта хендера (кроме `Server::ClientSocket`, который передается автоматически).
На каждого пользователя создается свой объект хендлера, поэтому имеет смысл передавать некоторые объекты по ссылке -- например, общий для всех клиентов на этом эндпоинте пул потоков.

Например, вот так добавляется хендлер, который просто отвечает клиенту его же сообщением:
```cpp
server.set_endpoint<Server::Handlers::EchoHandler>('e');
```


